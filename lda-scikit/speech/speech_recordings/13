Lacoste-Julien Simon
00:00:00
Ok recording as started
00:00:05
So today we'll finally talk about directed graphical model, which is part of the title of the class.
00:00:14
So basically we have a bit of class. So basically in the last few lectures I talked about simple two nodes graphical model.
00:00:25
Sorry about that, and particular we did regression. And then we also talked about latent variable model where we had this mixture of Gaussian. So now we will talk about more general graphical model structure, in particular in preparation for the hmm structure where we have a time dependence.
00:00:46
And so the menu will first to do a bit of
00:00:51
Graph theory, a bit of review on graph theory because this will be important for
00:00:58
The properties of graphical model and then I will finally define directed graphic model in and their properties. So today we'll start with a bit of graph theory review.
00:01:10
Or if it's the first time you see it, you will learn that
00:01:15
And then talk about Derek a graphical mall.
00:01:21
So,
00:01:24
So again,
00:01:26
Terms of big picture.
00:01:29
I mentioned that
00:01:31
The idea of a graphical model is to combine
00:01:35
So a graphical model.
00:01:39
Is a way, it's basically combining property theory.
00:01:50
You know, I have a problem with my writing. This was problem.
00:01:56
Here we go, primacy theory and computer science.
00:02:01
And so from property theory basically were talking about modeling the distribution of random variables of multi dimensional data. So we have a collection of random variables are just big random vector and we have each of these components is random variables.
00:02:18
And from computer science, who basic talk about will use
00:02:24
Notions from graph theory to be able to efficiently represent these distributions and menu played them using you know concepts from that that structures for computer science and graph theoretical notions such as
00:02:43
traversing a graph or passing messages on the graph.
00:02:47
Okay. And so the idea of the graph here is to provide an efficient that that structure.
00:02:56
To handle these huge
00:03:00
Complicated distributions.
00:03:04
And in particular with the graphical model, we can deal in a unified fashion.
00:03:11
A lot of different distributions. So, so from a coding perspective, it's very useful to have this uniform unified interface and way to deal with like pro stick influence
00:03:23
And to give you an example of what we mean by efficient that structure. Suppose, again, that I have n random variables.
00:03:35
Which are binary right let's say x i is 01
00:03:41
And let's say n is basically in the hundreds
00:03:59
And so
00:04:02
I don't have coven I just met with Legos.
00:04:08
And so, if n is a hundreds
00:04:12
Then the number of possible joint assignment to my end variables is to to the hundred
00:04:20
And so
00:04:22
To specify in general distribution over these these hundred random variables. I need 200 to two day race to the hundred numbers.
00:04:37
In a table. And so this is intractable.
00:04:47
And so a concrete example of that is in this queue, Mr model that I mentioned I think it'd be in their classes and motivation, where some of these random variable represent the presence or absence of some diseases.
00:05:07
And the you will then observed
00:05:13
The variable at the bottom, which are the symptoms.
00:05:19
And then I have this complicated graph structure with could say that. Oh, if you have. I don't know. Care act as your disease, then some stuff happens through your eyes and this is encoded in this
00:05:33
In this basically graph structure here.
00:05:40
And so we'll see when we define our diapered graphical model how this graph structure translates to assumptions about the distributions, which can be exploited for more efficient.
00:05:57
And friends as well as statistics. So learning
00:06:02
And what does camera stand forward. I think it's I
00:06:07
Think the M is for medical and the q&a are. I don't remember actually. So it's Google it.
00:06:16
It's for fun, because I forgot.
00:06:21
To Mr.
user avatar
Unknown Speaker
00:06:25
Symptoms.
user avatar
Lacoste-Julien Simon
00:06:40
Oh, quick medical reference Olga.
00:06:47
I guess that's what because there's a queue, Mr DT Beijing network with 4000
00:06:53
Symptoms and 500 disease.
00:06:58
Yeah, I guess it's quick medical reference. So the idea there is that this network will be encoding prior information which has been gathered from like
00:07:08
Experts and medical know legend. So you encoded in this network. And then you can use it to do a conference on. Oh, I have observed the symptoms, what are the most likely diseases which could have caused that
00:07:25
Alright, so let's start. So that's the motivation for
00:07:30
Having these data structures. So let's do a bit of a graph theory review.
00:07:43
Going by the way the queue, Mr thing is also something where, actually, it turns out that doing in France in these graph is intractable exactly in France. So you need to do approximate in France.
00:07:55
And popular divisional approach that I've briefly mentioned in the past was a very efficient way to do it. And that's something for which Mike Jordan was known for in the 90s.
00:08:09
Like, is he was a leading figure in developing virtual method methods and one very important application was to be using these like big medical networks.
00:08:21
And so when we talk about version on France. We'll get back to that.
00:08:27
Okay, so
00:08:29
Let's define a directed graph.
00:08:33
Because that will be playing with these lot
00:08:37
So are directed graph.
00:08:41
Is also known as a di graph.
00:08:49
It's basically a set to know that and directed edges might. So here's an example I could have
00:08:58
Say 1234 and five, then I have edges.
00:09:07
Between my nodes and these edges or directed and so graph will use G to talk about our graph in this class. Some of these will be under Ted, some will be directed will still use G. And so the context would tell us if we're talking about a directed graph or not.
00:09:25
And then
00:09:27
It's represented as a couple of
00:09:31
V where v is the set of nodes.
00:09:41
For example, it could be one to end or one to d and these are called nodes or vertices
00:09:51
That's why I called the Vertex. Vertex
00:09:55
And he is a set of edges and it's actually a subset of the couples on the nodes. And so these are called directed edges.
00:10:14
And so, for example, this edge here.
00:10:18
I call he went to was Apple like he went through here, which is the directed edge from one to two is represented as
00:10:28
The double one two
00:10:33
Okay, and directed path.
00:10:44
I mean issues with my colors.
00:10:49
directed path in a in a graph is basically a sequencer is sequence of edges, such that the, the head of the edge is the
00:11:04
Base of the next edge. Right. So for example, I could ever a path from one to four in this graph, and I'll use the squiggly line to say it's a path from one to four.
00:11:16
And so it's it's basically a sequence of edges which are compatible in the graph. So this is for example.
00:11:22
Either the edge one to two and then one, two for the two to four, for example. So that creates a path or I could also have a different path which goes to the same node. So I could have one, three and then three, for example.
00:11:40
Okay. And so basically a direct path is a compatible.
00:11:47
Sequence compared the bull.
00:11:52
Comfortable I
00:11:55
Compatible
00:11:57
Sequence of edges.
00:12:06
And there's a set of nodes that we will use a lot in this class, which are the parents of a node so
00:12:17
Pi i and that sanitation, who will use it as a social convention, so pi is basically the set of parents have a Nolan a graph. So it's the set by definition. It's the set of nodes in my vertex set such that there exists an edge from this node to I, in my graph right so in my edge.
00:12:46
And so this is the set of parents
00:12:54
Of I
00:12:57
And so pie because of the Greek letter P for parents.
00:13:02
And so in this graph, for example, the parents of four would be those two notes. So, these, this would be pi four, which are the parents have node four
00:13:17
And then the children.
00:13:20
So there's like a parent child relationship. So the children are the
00:13:28
The nodes for which so children.
00:13:34
Have I
00:13:37
We won't have a special letter for the set
00:13:40
It's the same thing. Now, but in the other direction. Right. So it would be j in the such that there exists a know an edge from I 2G
00:13:51
In my edge sit
00:13:58
Okay.
00:14:00
So just setting up the notation.
00:14:03
So that's a directed graph. So what about the undirected graph.
00:14:07
So the undirected graph.
00:14:13
And under graphing
00:14:15
J Ji.
00:14:18
Ji Ji.
00:14:20
Ji Ji Ji. Yes. So it's also a couple v. So we use the same limitation. This all the their friends with the diagram is that the set of edges are not ordered topple they're just
00:14:36
Set of sites to they're basically two sets. So the elements where the elements
00:14:45
Of he
00:14:47
Are two sets.
00:14:52
IE set of two elements.
00:15:00
Okay, so does
00:15:03
We actually represent them not with a couple because a couple is ordered
00:15:09
We have, we use the notations curly brace because it's a set like i j
00:15:17
Is actually the same set as Jay i. So the way I the way I order my element in a set, doesn't matter because the set is not ordered
00:15:29
Versus I have that i j is not equal to Jay I when you think about the tunnel. So the order matters.
user avatar
Unknown Speaker
00:15:38
In a couple
user avatar
Lacoste-Julien Simon
00:15:42
Okay, and as an aside,
00:15:46
In this class we will never have self loops in our graph. And so the size of the, of the, the an edge will always be true. So there is no so there's no self loop.
00:16:03
In this class.
00:16:10
So I III. The size of any edge is equal to do so if you want to sell flute. You could present with a singleton edge like I that for present and
00:16:23
Nudge to itself.
00:16:26
And
00:16:28
So this is allowed and he is asking if we yellow cycles totally in in the undirected graphs, we're fine with cycles in a directed graph. We can also have cycle in general, but we'll see that
00:16:42
To define a directed graph model, we will have to have a second graph, which is my next definition, but let me finish the undergrad graph.
00:16:53
So let's do a little drawing similar to the one we had before so I will have 1234, for example, and now the edges don't have arrows, because they're undirected.
00:17:06
Yeah. And so in this case, I have a undirected path.
00:17:19
From two to three in this
00:17:23
In this
00:17:25
This graph. So it could be either this way, for example, or it could be this way. These are two paths which are possible.
00:17:35
And
00:17:38
Now because there's no direction in the relationship. We're not talking about parents or children anymore we're only talking about neighbors. So neighbors is a kind of like a symmetric relationship and so
00:17:50
Basically this the notion of neighbors.
00:17:56
will replace
00:17:58
The
00:18:01
Parents
00:18:03
Children.
00:18:06
Relationship from a diet graph.
00:18:19
And so for example before we had in in in the directed graph, we had the parents of four.
00:18:28
And we could have thought also about see the children of one, which are basically these two nodes here, we're not we're not talking about the parents of four will talk about the neighbors of four. And it's the same set as above, so two and three here. This is the neighbors.
00:18:51
Of node for
00:18:57
Or one for that matter. Can we could use annotation and I for
00:19:04
Neighbors, have I
00:19:09
Alright, so by definition, and I will be the set J such that in the
00:19:20
Sense that
00:19:22
There is a i j
00:19:27
In the butt here. There's no direction. So it doesn't matter if I put it first or second
00:19:37
So if critic is asking if probably Stickley does a self loop represent something different in a regular node. And I said, we don't allow self loop so they don't mean anything and interactive graphical model world.
00:19:55
Oh, okay. So Brendan is asking
00:19:59
Interesting question. Can we think of an underrated graph as a directed graph where the parents are the same as the children, ie, where every edge as a mirror image.
00:20:17
Well, in some sense, yes.
00:20:21
Like if you replace because in the sense like
00:20:25
In under the graph, the path or have no direction. But if if I if every edge is splitting in two edges in both direction, then I can replace my under at a pass in an under the graph which is directed path and they're all valid. They're all the same some sense.
00:20:45
So I think that's fine. I'm not sure. So for from an implementation perspective, it could make sense. I'm not sure if all properties are the same feels that would be careful with it.
00:21:00
But in this class. When we talk about underwriting graph, we'll just talk about this, these, uh,
00:21:08
These kind of set edges.
00:21:11
To not have to worry about direction.
00:21:15
Alright, so now
00:21:17
Somebody asked about, oh, can we have cycles. So let's talk about now as you click the
00:21:24
Directed graph. So let's define a DAG.
00:21:31
This is a directed a cyclic graph.
00:21:39
Is it a cyclic or a cyclic
00:21:44
I guess that's one, perhaps, where you have different
user avatar
Jacob Louis Hoover
00:21:48
It's not
user avatar
Lacoste-Julien Simon
00:21:48
Doesn't depend
00:21:52
So we went to you say it was taken.
user avatar
Loren Lugosch
00:21:55
As cyclic
user avatar
Lacoste-Julien Simon
00:21:57
And there is a cyclic
user avatar
Unknown Speaker
00:22:02
Okay.
user avatar
Lacoste-Julien Simon
00:22:05
Is there a consensus among the English speakers are actually you can say both. It depends on your, what you want to say.
00:22:17
Okay, some people say both. LIKE A. That's what I remember. But anyway, I'll say i a cyclic a cyclic. I think I forgot which one I was saying for it, but I'll keep saying whatever comes to my mind directed a basically graph.
00:22:32
It's a bag. So this is actually a directed graph. So I die graph.
00:22:40
With no cycles.
00:22:48
And the cycle is
00:22:52
directed path which comes back to the same node. Okay.
00:23:00
And this will be essential for defining or directed the graphical mode.
00:23:06
And something which is important, which comes with a bag is the notion of
00:23:13
Logical ordering
00:23:20
So,
00:23:22
An ordering
00:23:28
So basically, I'll take my set of nodes and I'll order them in a specific
00:23:38
Way.
00:23:42
One up to V
00:23:48
Is said
00:23:51
To be logical.
00:23:56
Paula Jake call for G.
00:24:04
If and only if
00:24:07
The nodes.
00:24:09
In the parent of I
00:24:12
Appears
00:24:15
Appear before
00:24:18
I
00:24:22
In the ordering
00:24:27
And this is true for all high okay i III. Suppose
00:24:34
Jay,
00:24:36
was apparent of I
00:24:39
We need to have that in your order we have put J.
00:24:44
Before
00:24:47
I
00:24:48
Okay, so basically I is mapping all the nodes in a in an order from one to the size of v. So, it's called the end
user avatar
Unknown Speaker
00:24:56
It's indefensible to end by
user avatar
Lacoste-Julien Simon
00:24:59
We will always have, and sometimes will become D or sometimes there's other letters which will represent the number of variables but for now it's us and
00:25:07
And the idea is you order all your notes, such that
00:25:12
The children appear after the parents. Okay, which means that because the arrows goes from parents to children. It means that if you order the nodes.
00:25:28
You know, from left to right. That said, This is my top logical ordering all the arrows actually goes to the right.
00:25:38
And here I have it turns out that in this first graph that I put here 1234. This was already in topological order to the 1234 was in topology corridor.
00:25:51
Again, and these are the here. I've just drawn the the edges. And you can see that all the arrows are always going to the right.
00:26:00
Okay, so, so when you have a topological ordering. So one, one way to quickly see if you ever to political ordering is whoops.
00:26:11
Is that there is no back edge.
00:26:16
Or during
00:26:18
All edges.
00:26:22
Go from left to right.
00:26:32
So there is no
00:26:35
back edge.
00:26:45
Okay.
00:26:51
So why do we care. Well, so we'll see that will prove some properties for DR graphical model, which will use this property in the fact that when we
00:27:01
Go down through the list of nodes. For example, let's say we start to do stuff here. We start to do stuff there, then we're sure that
00:27:08
We won't have a little edge going back like this, which could create some weird dependencies, or make things simpler and screw up or or arguments. Okay, so that's why it's actually quite helpful to have this order, we get a bit of a handle on the, the, the parents child relationship.
00:27:30
And then an important proposition.
00:27:35
Is that it is for. If you have a graph, a directed graph G.
00:27:43
Then it is a bag.
00:27:49
A DAG if and only if there exists a topological ordering
00:27:58
Polo.
00:28:00
Polo Jay call ordering on Jay
00:28:11
And so intuitively it makes sense because
00:28:16
If I have a cycle, then there's no way I can have it to political ordering because the cycle will have an edge going like this and then they will also have an edge coming back.
00:28:28
So let me do the proof because it's very simple and gives you a bit of
00:28:35
Practice with proofs. So the implication from the fact that if there's a topic called ordering, then it's a direct the doctor graphical Margo, it's basically trivial. It's what I just explained so because there is no back edge in your political ordering
00:28:53
There's no way you can create a cycle. So there's no cycle.
00:28:58
Because to come back to a node. You'll have to, let's say you follow the path. So you'll go to the right. And then at some point you have to come back soon. They have to have an
00:29:09
Edge, which goes the other direction in that contradicts the property of a topological order.
00:29:16
Now let's do the other application, which is that
00:29:21
If I have a DAG, then I can construct the political ordering. So how do you do it well. So the way to do it is you use the depth first search algorithm.
00:29:34
On the graph to kind of like you start anywhere. And then you go as deep as you can.
00:29:41
And then what you do is you
00:29:45
To label.
00:29:48
Nodes.
00:29:50
In decreasing
00:29:54
Order.
00:29:57
When
00:29:59
Have no children.
00:30:04
So basically the idea is let's say there's a there's a graph. For example, let's let's do it like this.
00:30:12
Use a random graph.
00:30:18
Okay and I start somewhere. So I'd say start here.
00:30:25
And then I do that for search. What does it mean is, you, you, you, you go through all your, your, your, your children, but you
00:30:33
You, you, you rehearse first by going as deep as possible. So you would stay choose this one, then you would choose this one and then you would be stuck because there's no children. Okay.
00:30:43
And so because this node has no children. I can put it at the last of at the end of my ordering because it has no
00:30:52
Edge. So there's definitely no back edge. Right. And so I'll say, and I have five nodes us okay this is five.
00:30:59
Okay.
00:31:01
And then I go back in my depth for search algorithm. And each time. I'm only looking at nodes which has been visited. So it's like if I had no children. So for example, this node here.
00:31:17
In this case, because I already labeled it's child. It's also has no children. So I could now put the next one I could say this is for
00:31:26
And then I'm not allowed to say this is three because this one has another children. So then I need to keep rehearsing my debt for search first and then visit all its children. So let's do that.
00:31:42
And so now I would, for example, call
00:31:48
Visiting the children of the, the, the, the second child of this node.
00:31:55
Oops. This was for us it
00:32:00
And now I get a node.
00:32:04
So this node here.
00:32:06
Because this one has already been visited. I don't have to keep going. So it doesn't. It has no children. So now I'm allowed to give the next available number. So, this will be come through.
00:32:20
And then the last note which I have not visited
00:32:26
Well, okay. So first of all, now
00:32:31
This could be too because all its children has already been visited
00:32:35
And then I have my last node, which I could start again from because I didn't know. By the way, I said, Start somewhere because you don't know which one is the route necessarily
00:32:45
So, but, yeah. So here's by doing that first search on this thing. I basically constructed the logical order.
00:32:53
And by construction, because I always only put node, which they don't have any children, which I've already been visited then I won't have any edge going to the left. So I constructed at the top political sort
00:33:10
Okay, so, so you can do this to construct
00:33:15
A sort
00:33:18
And this is in
00:33:23
Order size of the number of edges blahs number of nodes. So that's the running time of depth for search for this.
00:33:32
And the reason you can continue doing this algorithm is because there's no cycle because no, sorry.
00:33:41
I had to political ordering. No, this is I had a dad. Yeah. And so you know that you will always be able to have no back edge by the property. Again, that there's no cycle. So it's all circular
00:33:58
Okay, so I mean that was a bit of a fast proof. It's normally would be a bit more detail, but this is just to give you the idea
00:34:07
So is there any question about
00:34:10
This these simple graph concepts.
user avatar
Unknown Speaker
00:34:25
OK.
user avatar
Lacoste-Julien Simon
00:34:27
So now the plan is to introduce a bit of notation.
00:34:32
And then we'll talk again about
00:34:36
And then finally we'll define what a diagram graphical model. So let's do a bit of meditation.
00:34:48
Meditation.
00:34:51
For graphical model.
00:35:04
All right.
00:35:22
So some people ask about why did they use that for so that that first search idea was to find leaf very quickly and then once you find a leaf. I need somebody with which don't have any children, then you can label them at the end of your order.
00:35:40
Could you do it in the other direction. I don't think so, though it could be the algorithm. I know is you do that first search to do that to find the top logical sorting.
00:35:57
But if you want to know more. I recommend that you can just look the political sort for in Wikipedia, for example, they will tell you more about this algorithm. It's pretty standard for
00:36:10
A graph algorithm.
00:36:13
Alright, so
00:36:17
Alright, so first of all, we will use
00:36:21
So suppose we have an discrete random variable.
00:36:26
X one lab law to excel.
00:36:29
And
00:36:31
For a lot of ours, the stuff will do for graphical model, we will assume
00:36:38
discrete random variable for simplicity
00:36:45
Even though. Yes. A lot of these concept applies on continuous distributions.
00:36:51
But
00:36:53
For getting the simplest result first will use with think of discrete random variable. And the reason is discuss conditioning for continuous random variable is super complicated. So the conditional distribution.
00:37:08
Concept is actually very tricky to formalize
00:37:16
So right now in this class. I kind of swept this on the direct by just saying, Oh, we will define some kind of conditional density, we will have distributions, where we have these conditional then cities.
00:37:26
But if you take a formal protein class, you will learn to actually the conditional distribution is it's not a
00:37:35
Simplistic quantity. It's actually a random variable. Everything is a random variable. So conditional expectation is a random variable. All these things are random variable.
00:37:43
And and they're only defined almost surely so it gets things a bit more tricky. And if you're curious about that. I will say, see the borrowed call marggraf paradox.
00:37:59
Isn't the combo GIRL, GIRL, GIRL como growth.
00:38:05
Paradox.
00:38:07
On Wikipedia, which will
00:38:12
Yeah, so the Broadcom or grab that paradox on Wikipedia, which tells you
00:38:17
A bit where this trickiness come from. So this is basically the paradox tell says like, oh, if I want to define say have a uniform distribution in a sphere.
00:38:27
Okay, that's pretty simple to think about. Now I want to condition. I want to look at what's the conditional distribution in the sphere given I'm on some great circle.
00:38:36
So, oh, I'm I know I'm on a great circle, which is an event of properties zero on first thing that's already a problem. So you want to condition on the vendor for the zero and then I wanted to find out what's my conditional distribution.
00:38:48
And then depending on how you split your space, you'll get different answers and the splitting the space is coming from these boreal sigma algebra, which are the sigma field. Sorry, which tells you how you will want to define
00:39:07
What, what kind of policy statement, you want to make and your and there's different ways you can do it in this case.
00:39:18
Some people are making jokes about the order of the names
00:39:23
Yeah, so if you're in Russia. It's probably the Komodo have borrowed paradox. But Wikipedia in English. It's broken marggraf
00:39:33
And so if you had no idea what I just talked about. Don't worry about it. And if you're curious. Just have a look at the article.
00:39:40
Though, but keep in mind that to really formalized these understand how to resolve these paradoxes is very tricky. Okay, so that's the unfortunate aspect of having these these continuous distribution and trying to condition on an event of
00:39:55
Property zero
00:39:57
But when you have a discrete random variable, you don't have to worry about that.
00:40:02
Okay, so basically v in our graphical model. This will be the set of vertices
00:40:12
And the thing is, in a graphical model.
00:40:15
We associate one random variable per node. Okay.
00:40:20
So there will be one.
00:40:23
Variable
00:40:25
Random variable.
00:40:28
per node.
00:40:31
Okay.
00:40:35
So the nodes in our graph will be associated with random variables. And then the edges. We were present potential dependencies between my random variable.
00:40:45
And then the joint.
00:40:52
Of my random variable. So like P of X one equals little x one, blah blah blah, p of x n equals his little accent.
00:41:02
So,
00:41:04
I could just write this as
00:41:11
P of little x one, blah, blah, blah. Too little accent.
00:41:20
Even though you know like the little x's. Normally, or just dummy variables right they do represent possible and sensation, but I could use
00:41:29
Z or V or a or I could use any variable I want, but because we want to use a lot of like
00:41:37
shorthand notation in this graph in this class because otherwise it takes forever. So the fact that we use little x one.
00:41:44
will mean that all this is the possible value of the capital X one random variable, not the capital X, for example, though sometimes if we talk about relationship between values we might have capital X two equals little x one, but usually
00:42:01
This will be the Convention, which is why that
00:42:05
The in this sense, when I write this quantity here, it's clear that little x one is the value for capital X one and it will extend is the value for capital X, then
00:42:16
And then what we do is we were allowed to also use
00:42:20
Sets as substrate. So we can rewrite this SP of
00:42:26
Little, little X, capital V as a subscript. Okay.
00:42:31
Because for as I think we are. I'm not sure if I already had defining the stats, but you've seen it in my book. So if I have a set for any subset of V
00:42:42
I can define the marginal
00:42:46
P of X A, so this is by definition the quality
00:42:57
That
00:42:59
Capital X is equal to little excited for i in a okay
00:43:10
And so, so this a year is a way to get a subset
00:43:15
Of sub scripts.
00:43:21
And so this is actually a marginal because if a is not all the V i have a subset of variables there. And so by this is the marginal. How do you get the marginal. Will you need to some overall X for the other possible values.
00:43:38
Of for my other variables which are not in it. See, so a compliment. So super script see
00:43:47
Of the joint. Right. So this is pls A x a compliment. Right. And this is something
00:43:59
Over all
00:44:02
Possible.
00:44:05
Values.
00:44:07
Of
00:44:10
X i.
00:44:16
For I in the compliment of it.
00:44:21
I guess I can rewrite it more explicitly as v minus a and this is what we mean by a compliment. Right, so V capital V is the universal universe set just from the context.
00:44:36
So notation wise. If I think of X subscript say the set one to four.
00:44:44
This is the same thing as thinking of X one, X two and X four I can expand my subscript like this.
00:45:03
And often will just use x for the old concatenation of my
00:45:11
Observation. So, x one up to n.
00:45:15
And us
00:45:18
Sometimes we'll just right p of x ray
00:45:22
Instead of X subscript capital these substrate capital V is kind of understood
00:45:31
Okay so Dora is asking, Isn't the marginal here a joint over the observations in eight though. Yes, correct.
00:45:40
Yes. So, so that's a interesting way to talk about it. So from the context of the joint over all the variables.
00:45:50
X A is a marginal right so I need to some. So this is a joint overall variables. I have the variables in a and the variables which are not in a that
00:45:59
That's all my variables and then something out all the values in x, a compliment. I'm just left with the property or next but then if we only care about the variables in a we couldn't think of p of x A as the full joint on all the variables in it.
00:46:17
So that's accurate.
00:46:24
And the other question.
00:46:27
I mean, I think I've kind of talked about this notation before
00:46:32
So far as there's an interesting subtlety, which I'll mention here. So is, for example, p of x one x two x four equals
00:46:45
Two p of x two x one, x four.
00:46:54
And so
00:46:56
Is the ordering in my tea important and normally in math. Yes, definitely. So they would not be equal, unless you have specific properties. But in this class. It's actually yes usually
00:47:12
In this class.
00:47:17
We will use basically
00:47:21
The typed convention.
00:47:26
What I mean by type convention. So you could think of these variable has having a type. Like, for example, like when you do computer science and you program a function, you could have
00:47:36
You could pass a variable which has been declared an RA, or you could be declare a double. So these are different types
00:47:44
And in particular, you can do polymorphous ism, which is depending on what you call the function with or even the type of the thing you call with
00:47:52
You will have different implementation. Okay. And so here you can think of the variable name we use x one x two x four as defining the type, meaning that
00:48:04
X one will mean. Oh, this is the values that the capital X one takes and I don't care where I put it in the order. So for example, I could put x to first. If I want to next one after that.
00:48:17
I still associate X little extra to the value that capital X two tix. Okay, so there's no order notation.
00:48:27
Usually though sometimes if I want to talk about flipping the values of something around and putting it in my joint, then you will have that these are two different
00:48:40
Distribution, so it will be clear from the context, but usually
00:48:44
Will have that those two things are equal in this case.
00:48:57
Yeah. So to clarify something here. So this is something over all possible values of x i.
user avatar
Unknown Speaker
00:49:05
Can take
user avatar
Lacoste-Julien Simon
00:49:22
Okay, so
00:49:26
Last thing to talk about before we take a break.
00:49:31
And then we'll finally define what a director graphical model is
00:49:37
So let's revisit conditional independence.
00:49:43
Because it's going to show the dependence before was defined with like individual variables. Now we'll define it with set of variables.
00:49:51
Oops, with our new notation powerful notation. So let's revisit
00:49:58
Conditional independence.
00:50:03
So now, let a
00:50:06
B and C, the subset of my ground said capital D.
00:50:14
So if I say that x A is condition, independent of x be given X see
00:50:24
There's two ways to talk about it. The first one is the factorization definition. So the factorization definition would say that, well, when I looked at the
00:50:36
Conditional of x A x be given X. See this is factor rising as a product. So, x A given exceed times probability of x be given x and this will be true for all x A x be tech see such that the probability of XE is positive.
00:51:03
Can only condition on positive property things
00:51:07
So that's the factorization definition of conditional independence. But there's another one which is equivalent, which is the conditional
00:51:16
Perspective is saying that, well, if I condition on both x be an XE
00:51:23
Then because XP is independent of exceed knowing experience and change anything else. Once I condition and exceed. So it's the same thing as a property of a given X see only
00:51:35
Okay and this would be
00:51:39
For all x A x be x see such that the
00:51:45
Property of x be an XE is bigger than zero.
00:51:50
So if so either you have to factorization perspective of the distribution which tells you that there are conditional dependent or there's they're just the conditional. So either one or ways to to prove conditional independence.
00:52:10
And these are all in this case.
00:52:13
Probably tomorrow mass function because we're talking about discrete remember
00:52:17
And then in this notation, we can still talk about marginal independence.
00:52:23
IE not conditioning on anything.
00:52:27
Which was a standard independence. We first defined in this class. So we'll use annotation, say x A conditionally independent of XP. And normally, we'll just do that. But we can think, oh well conditioning on nothing.
00:52:41
Right. Or you could think of nothing as x empty set.
00:52:48
Right, so this is marginal independence, but if you don't put any conditioning. It's just the standard independence.
00:52:54
And that would mean that the basically this is just like P of x A
00:52:59
XP is equal to p of x, a time spirit. So that would be the factorization, or I also have the conditional version.
00:53:09
So, so where to condition on the empty set, just to talk about marginal independent
00:53:19
And two facts.
00:53:23
About
00:53:26
Conditional independence.
00:53:34
So one is that it will be
00:53:37
Convenient sometimes to repeat the variable in the statement. So we can repeat
00:53:43
The variables.
user avatar
Unknown Speaker
00:53:46
Oops, sorry.
user avatar
Lacoste-Julien Simon
00:53:53
In the statement.
00:53:58
For convenience.
00:54:06
So for example, we could write x is condition dependent of y and z, given z and w. Okay, so that's kind of weird because, why do I put z in both places. And so
00:54:22
Once I condition on z. If I put z on the left. It doesn't mean anything. It doesn't change anything because he becomes deterministic so it doesn't say anything. So this extra z here does not
00:54:34
Do anything
00:54:39
Okay, so it's fine to say this.
00:54:44
It's a weird statement because why would I repeat it. But when we talk about theorem, saying, Oh, these are all the conditional independent statements. Sometimes it's too complicated to exclude these repetition.
00:54:55
For simplicity. So then we will allow the repetition, because what it means is, it is just that.
00:55:03
Like this is equivalent
00:55:05
This is equivalent
00:55:09
To just x conditional independent of why givens, and W. Right. So, so the adding Z's on the left doesn't change anything. Once I condition of them.
00:55:26
Okay, so this will be convenient in some of our theorems. And then there's something that
00:55:33
I think you proven Assignment one
00:55:36
So this is the decomposition property.
00:55:39
So the decomposition property says that if x is conditional dependent on y z given W. By the way, you don't need the parenthesis, like when I put y comma zero. That means the same as the joint of y AMP z, but just for more clarity here I can you put them as a joint
00:55:57
This implies actually to this is stronger conditional statement this in place two different statement, this implies both that
00:56:05
X is conditionally dependent why given w and x is conditional dependent of z given W.
00:56:12
It doesn't go the other way direction. Right, so it's not anything on the, if, if you could have that x is conditional of why given W and access conditional end of zig and W, but not conditional dependent on y AMP z.
00:56:27
The x. For example, if is one of that.
00:56:31
And I mentioned it in the past that recall that pairwise independence.
00:56:41
Is not equivalent to mutual independence.
00:56:47
So see, I think it's lecture three. I'm not sure. And I'm a bit late this year. So perhaps it was extra for but I'll write lecture three four now.
00:56:56
To be confirm. So, for example, by defining said is x
00:57:03
X or of why
00:57:06
Where x and y are independent. I had that all these pair of variables or pairwise independent, but they're not mutually independent
00:57:16
And finally,
00:57:19
One last property.
00:57:21
Is that by the chain rule.
00:57:26
We have that the joint on all my variables is equal to the product.
00:57:32
from i equals to n p of x i given x one up to i minus one for any ordering that I choose it is always true.
00:57:55
And so the last conditional
00:58:02
So the last conditional
00:58:06
Is p of x n, given X one up to n minus one. Right. And so for each of the value of my n minus one, parents, I need to give was a property of x n. So the number of possible assignment on the parents is actually to to the n minus one. So this is actually a table.
00:58:28
With to represent this conditional table with
00:58:33
Oops. There's too many with roughly
00:58:37
Two to the end entries
00:58:41
So this is why
00:58:43
Just reading the chain rule doesn't help.
00:58:46
reducing the size of our presentation for the joint.
00:58:51
And what will what will happen.
00:58:55
Is that the inner directed graphical model that will see after the break.
00:59:01
Is that will say that p of x d will be in this case the product over my nodes of p of x i, but instead of having all the previous variable will use only the parents in my graph.
user avatar
Unknown Speaker
00:59:17
OK.
user avatar
Lacoste-Julien Simon
00:59:19
And now I get tables in this case of size to to the maximum number of parents that I have plus one.
00:59:31
So if the number of parents is small. So, for example, it's a tree. So I have only one parent in a tree, then I get basically small table of size for
00:59:41
I will get n tables of sites for so I get like for an to represent my distribution which is much more efficient than to raise to the right. So that's the whole idea of a doctor.
00:59:52
That will see after the break.
00:59:59
AND THANKS SIMON for saying that the notation is elegant
01:00:03
Not sure which innovation, you're talking about. But indeed, this is a very convenient notation and
01:00:11
This is I'm not sure who came up with this efficient, but it's very useful for talking about these complicated object.
01:00:26
So sign so So Brendan is asking, why is it does a chain rule old for any ordering, not just the top logical ordering because when we talk about the chain rule, we don't care about the graph. We're just saying it's a joint
01:00:37
I just decide to start with one node. If the channel is proved. Just by the definition of conditional
01:00:46
Right, and so I don't need to. There's no property of the distinction to be used. So there's no notion of not adding a cycle. I just order my nodes in some order doesn't matter if it's, there's no graph associated with it anyway. We don't care about that.
01:01:05
Okay, so let's take a break. It's a 337 so we'll be back at 343 38 at 348
user avatar
Unknown Speaker
01:01:16
So let's take a quick minute break.
user avatar
Unknown Speaker
01:01:21
Resume recording
user avatar
Lacoste-Julien Simon
01:01:24
Okay, so one thing before I define a demographic a model is to highlight something
01:01:30
Which is that if I write this statement here. It's a circular statement. Why, because the conditional when we talk about P is normally define from the joint.
01:01:44
So the order would be I define a joint and then from the joint. I can compute it's conditional. But now I say that the joint is equal to a product of conditional
01:01:55
Because it's a it's a circular statement I have p on both sides of the equation.
01:02:01
It could be that there is no distribution which satisfy this property right so it there's no guarantee that is a well defined statements.
01:02:09
Which is why when we define a definite directive graphic. I'm all in the way I will define it. I won't use these conditional and the right because it's a circular statement, we will prove
01:02:19
well defined. First, are there think Africa model and then we would prove that from this definition we do get this property that I just defined and it's about it. Okay.
01:02:28
So let's do that now.
01:02:31
So what is a dark graphical model.
01:02:46
So first of all its associated with the graph. So let g
01:02:50
With edge set V sorry nodes V and edge. He be a bag. So it has to be from directed graphic I sickly graph.
01:03:02
Then
01:03:05
Directed to graphical model.
01:03:16
Also abbreviated as the GM
01:03:26
And implicitly when we talk about the the gym. It is associated with a graph.
01:03:38
And
01:03:40
It's also known by the way.
01:03:43
Also known as a Bayesian network.
01:03:53
So what's the Darth Maul so I definitely got from the model. It's a family of distribution.
01:03:59
It is not the single distribution. It is a family of distribution.
01:04:04
And that's a very important point to keep in mind. And it's subtle and confuse a lot people at first, but it's a set of distribution. It's not just one
01:04:14
And the reason why we talked about that directly graphical model is that it enables us to treat a lot of different distributions, the same way with our code and stuffing methods. We talked about their properties.
01:04:27
So it's a family of distributions over
01:04:31
X XV. So the random variables associated with our nodes.
01:04:40
And we use a notation script L of G in this class. Okay so script L of G that will represent the family of distribution of a with which is a directed graph model. So what are the distributions in this family.
01:04:59
So what are this mission in my script LG. Oops.
01:05:05
I am having issues with my pen so
01:05:10
It will be a distinct set of distribution P such that p is a distribution.
01:05:19
Over XV.
01:05:22
Such that it has specific properties there exist legal
01:05:30
Factors.
01:05:33
F eyes.
01:05:36
Such that the joint p of x, v is equal to the product of these factors if i X i given x by
01:05:55
Four. All right, so
01:05:59
So basically,
01:06:01
The distribution which lies in my family or distribution which factor is in a specific way where you have these these factors here which only depends on the parents. So I guess I could perhaps put it more. I will highlight that. So the whole
01:06:19
Where the where the graph comes into play here is that
01:06:23
You will have that the factor is only are allowed to depend on the parent of I. Oh. Oops, wrong pen expire. I
01:06:32
And what does it mean to be a legal factor.
01:06:37
So illegal factor is basically a function from the possible values of x i cross the bus civil values of my parents.
user avatar
Unknown Speaker
01:06:51
So these are the
user avatar
Lacoste-Julien Simon
01:06:53
The simple the
01:06:57
How they call these omega sample space expire. I
01:07:03
201
user avatar
Unknown Speaker
01:07:07
Okay.
user avatar
Lacoste-Julien Simon
01:07:09
So there are positive such that Dr normalized, so if I some over X I, my factor x i, and I could put a comma, instead of a given but you know
01:07:24
Perhaps, let's put it
01:07:27
Expire I just notation that could could come are given, you don't have to. And as you know, it isn't discuss often I put given sometimes I put come out, or even semi colon.
01:07:39
So this sums to one for all expired.
user avatar
Unknown Speaker
01:07:45
Okay.
user avatar
Lacoste-Julien Simon
01:07:46
And so basically these factors D look like a conditional distribution, because they're positive and is some to one. And so basically Fri. This implies that FBI
01:08:01
Is like the complete conditional policy table so CPT
01:08:08
Conditional
01:08:12
Probability.
user avatar
Unknown Speaker
01:08:14
Table.
user avatar
Lacoste-Julien Simon
01:08:16
CBD is just a fancy word to say, oh, how do you present the conditional distribution. Well, it's a table, such that you say on the Rosa possible values of x i on the columns, all the possible they use the parents and you have that when you somewhere on the column, it has to some to one.
01:08:36
So that's a directed graph of them all. Let's put a little square on it.
01:09:13
Okay so Umar asked, why is it also called a Bayesian network.
01:09:19
I think the idea is if you're a Bayesian, you have to define a distribution over everything that is uncertain.
01:09:28
And so
01:09:31
The fact is that these these these graphical model is a very powerful and flexible.
01:09:40
Formalism to define complicated distribution in particular for a Bayesian so they're very useful for Beijing to encode their beliefs.
01:09:48
So usually you can use a Bayesian network to encode the beliefs of a patient, even though you can also use a vision network to do something which has nothing to do with being Asian, just define distribution, but in particular Beijing's will will love Beijing networks are different model.
01:10:06
The difference between a Beijing in Beijing will be that the parameters and this kind of stuff would not be known.
01:10:13
In standard frequent this framework because they're not random variable was a Bayesian would also put these random variable. Sorry, these, these parameters like theta, this kind of stuff as random variable as well.
01:10:31
Okay, so that's a D GM
01:10:35
And the terminology is
01:10:41
So we'll say that, let's say if we can right
01:10:50
For some distribution, the joint as a product over factors where
01:10:58
You get this parents relationship. And so the pie I here. This is what determine G.
01:11:09
This determines the edge set. And so then we will say,
01:11:15
That p
01:11:18
Factor rises act or according to G. P. Factor rises.
01:11:26
According
01:11:28
To Jesus
01:11:33
That's the terminology. And so the GM is a set of distribution which factor is according to the graph that we use to define the DJ
01:11:53
Alright, so somebody is asking your question here.
01:11:58
They're confused by the rotation.
01:12:02
Excited much as if I index and expire. I am. So the point here is, so for each node. I have a factor. The factor will have to have X I, as the argument.
01:12:16
And x pie as the thing you can condition and on i. And so, you know, you have to look at what are the parents of it in the graph. Okay, so that's my factor. And now if I some over the passive value of x i. So, is fixed here. If I some just a word, the values of x, I get one.
01:12:38
And and this has to be valid for anything I conditioner and that's why it's for any expired. I and you you have that this is true for all eyes.
01:12:47
This is clarify the rotation, Simon.
01:12:54
Sure. So if, if you want to be very formal. You say, for all i.
01:13:00
So here basically, I was just defining quickly what we mean by legal factors. So for any if I it's a legal factor if it does this property and because you know I use a lot of fit in my definition, then of course the to satisfy these property for all eyes.
01:13:41
I'm sure Jacob, and are there any methods to learn. G. If it's unknown.
01:13:49
Yes. So this has to do with the problem of model selection.
01:13:55
So some sense model selection. Is it possible models to talk about my my data which model should I use for example I could also choose between different
01:14:03
Parametric family of distribution. Should it be a garden should be a song and you want to choose that. So this is called the model section problem one molestation problem would be well which graph. So they used to talk about my my data and there are methods for that.
01:14:19
And we'll talk about it when we talk about model selection.
01:14:28
Okay, so let's give you a simple example. So, for example,
01:14:38
I could have this graph here on three random variables. I have x y as parents to Z.
01:14:46
Right.
01:14:47
And so if my distribution belongs to the graphical model.
01:14:53
Represented by this
01:14:55
Graph.
01:14:57
Then it's joint
01:15:01
There exists FX f y AMP Z legal
01:15:09
Such that the joint over y x, y, and z is the product of these factors. And so, and the factors has to respect the parents relationship. So x didn't have any parents. So it's just f of x, x
01:15:26
The factor on why has also no parents that will be why and then they will be a factor on z, which has two parents that would be z given x and y.
01:15:40
OK, so the distribution p which factories, according to this product with any type of factors there. The one in this
01:15:49
That could graphical model. And this is actually called a V structure and we'll get back to this very soon. It's basically the most interesting piece of data graphical
01:16:03
OK, so now
01:16:05
The next step will be to show. So the next step is to show that basically
01:16:13
These conditions are the same as the factor.
01:16:18
They're the same.
01:16:19
Which is why I'm allowed them to write this because we have that p of x is a problem factor and these factors are the conditional. And now I didn't use it visible link. So that's raised that, but we need to prove that
user avatar
Unknown Speaker
01:16:35
That
user avatar
Lacoste-Julien Simon
01:16:56
Okay.
01:16:58
So,
01:17:01
Before proving that the basically the conditions are just the factor.
01:17:08
I will prove something which comes in all in a lot of proofs.
01:17:13
For the GM, which is the leaf lacking property.
01:17:24
Which is basically a fundamental property of their traffic model.
01:17:40
So what's this leaf plucking property.
01:17:43
It basically means that when you marginalize out the leaf in a directed graph model. It's just removing this factor. And then you keep everything else the same. Okay, so let p be a member of the doctor graphical model family. And now let n b a leaf.
01:18:06
dingy
01:18:09
IE and
01:18:13
Has no children.
01:18:16
It's not the parent of anything.
01:18:20
And if n is not a leaf in G just rename your nodes from you the name of the nodes, such that any day.
01:18:29
So that's would be without loss of generosity.
01:18:32
So what are we proving with the leaf plucking property is that if we look at the marginals
01:18:41
On all the variable except n
01:18:45
Well, first of all, this marginals is a joint on a smaller number of variables, which also belongs to a directed graph model. It belongs to the data graphical model where I have removed and from my graph. Okay, so this means
01:19:02
This notation here means take the graph G and then remove
01:19:09
node n
01:19:12
To know nude and from G.
01:19:18
So it's a smaller graph on the smaller number of nodes you keep all the same edge from the other graphic 71 which were connected to him.
01:19:29
And moreover, not only belongs to this, the GM, but we have a very simple
01:19:38
Expression for it. If P of X one up to n. So if my joint for this be was a product of these factor.
01:19:52
X i, x by I
01:19:56
Then the marginals when I removed the last
01:20:01
Variable
01:20:03
Is the same product with the exact same factor, except that now I have a product over n minus one. And I try basically just remove the last factor.
user avatar
Unknown Speaker
01:20:17
Okay.
user avatar
Lacoste-Julien Simon
01:20:18
So if and is not a leaf. You don't have that. So it's very specific to know being a leaf. But the nice are very nice. You can plug them you can remove them from the graph and things are super simple. You just remove the factor. And then everything else stays the same.
01:20:35
So, the proof is very simple trivial.
01:20:40
So, probability of x and x one up to n minus one. So that's my joint
01:20:47
By definition of a graphical model, it will be the product of fn
01:20:54
X and X by n. So in some sense, there exists some factors as it's true.
01:21:01
And then I will have product over all my other nodes.
01:21:06
So let's see. Gina equals two, n of f g h i j x by Jay
01:21:17
And now because n
01:21:24
So let's start talking about it is yet. So now I want to compute the marginal. So the marginal were only having one up to n minus one, I need to some over accent my joint
01:21:40
And so now I need to sum.
01:21:44
This thing over accent. This whole thing. And now the key property is that
01:21:53
Because and is a leaf. It doesn't have any children IE. It's not the parent of anything. And so there is no n anywhere in these expression in any pages. Okay, so, and
01:22:10
The x and variable all me appears here. So when I some over accent. These thing here is a constant, there was no accent anywhere. And so I can just write this as summation over accent I can factor is it out. If an ex an invisible ink.
01:22:33
Summation of Rick extend fn X and given x by n.
01:22:40
And then the rest is just a constant for
01:22:44
SN Fj xj x by Jay
01:22:52
And so that's why I was able to factor is it like this. And so now, this by definition of the factor is just equal to one.
01:23:03
By definition of the factor.
01:23:08
And so I'm done. I've proven both that
01:23:12
The marginal was just this simple product here. Like, I wrote here. Sorry, this one here and
01:23:21
And these parents relationship satisfy the one from the graph where I just removed the leaf.
01:23:38
Okay, so somebody is asking something about my notation. This is. Oh. Well, isn't the the set minus notation. This slash thing.
01:23:47
Well, the thing is that g is not a set g is a graph. Okay, so I use minus just to define a subtraction notation on my graph. And anyway, this is just location. I'm using right now I'm defining
01:24:02
Graph minus set of nodes as removing the nodes in my graph, but it's not the same thing as removing elements of a set because Jesus, not a set. It's a couple both of nodes and edge. So you need to kind of like, do a lot of
01:24:16
It's both removing the the the node from the node set, but also the corresponding edges which are connected. So it's a much more complicated operation that just removing some elements.
01:24:33
Okay. So, is it clear this leaf property but plucking rotation. So if I just remove if I want to marginalize out a variable which is a leaf in a dark, the governor model, you basically just remove its factor and that's it you're left with the correct Marshall.
01:24:51
So now let's prove its use this property to prove what I was talking about.
01:24:56
The proposition.
01:25:02
So if
01:25:04
P is a factor is according to graph is a member of a doctor graphical model.
01:25:12
Then let
01:25:14
F j
01:25:16
Be a factorization.
01:25:24
With respect,
01:25:25
To je je je je for p
01:25:33
Then it turns out that for all i.
01:25:37
The conditional of p on exile, given its parents is just equal to this factor.
01:25:50
For all x by I
01:25:53
IE. The factors.
01:25:57
Or the correct conditions.
01:26:06
And because the conditional is is determine from the joint that also means that the factors are unique, by the way.
01:26:16
Because I never said with the definition that the factors had to be unique. It didn't rule out in a definition that there could be two different factorization, which are both according to the graph it, which gives the exact same joint, but there are different factors.
01:26:35
But because the factors have to be equal to the conditional and the conditional or a specified by the joint, then they are unique.
01:26:47
Alright.
01:26:49
So I'll do a bit of a not super clean proof, but it's just to give you the idea
user avatar
Unknown Speaker
01:26:57
So,
user avatar
Lacoste-Julien Simon
01:26:58
In some sense, normally the way you really prove that is by induction. But I'm a bit lazy. I don't want to do the induction hypothesis and stuff. So the way I do it is, I'll say
01:27:09
Let one up to n.
01:27:13
Be a topological
01:27:16
Sorting
01:27:19
The political sorting is just a political ordering. It's the same thing.
01:27:24
Of G.
01:27:28
And this is possible.
01:27:31
Because
01:27:33
G is a bag and I said that all DAG had a topological ordering
01:27:45
And so I called one up to in the political sorting, meaning that
01:27:50
I assume that my nodes names were already in the correct of logical order. If it's not the case just renamed them right so you had, for example, the original one.
01:27:58
Up to end nodes. They've been mapped in an order which flip them around. Now just rename these nodes with the their order the political sort sorted order. And that work.
01:28:12
So now, let it be fixed.
01:28:20
So we want to show
01:28:25
That the conditional p of x i given x by i is just equal to f
01:28:33
X i given x by I
01:28:38
Want to show that
01:28:39
So the way we'll do that is just pluck all the leaves up to it.
01:28:44
So,
01:28:46
By the logical sort of property and cannot have any children because the children are only before so it would have it back edge. So we know that n is a leaf.
01:28:58
So then just pluck it
01:29:00
I E marginalize out accent.
01:29:04
To get
01:29:05
Probably T of x one up to n minus one.
01:29:09
Is the product J one up to n minus one of f g xj x by Jake
01:29:21
And so now, what I get is a factorization.
01:29:28
For a DAG.
01:29:32
Where x minus one.
01:29:37
Is now.
01:29:39
A leaf.
01:29:42
Right, because I remove and so all the edges from which are connected to, and is now removed. So now I'm n minus one and minus one is still in if it could have an edge to end but and is not there anymore, so n minus one is now leaf in this new graph. So I can also pluck it
01:30:00
So then, like it as well.
01:30:04
Luck and minus one as well.
01:30:10
And so you keep doing this.
01:30:14
Doing
01:30:16
This
01:30:18
in reverse order plucking each leave
01:30:22
Using the fact that you have a topological sword that these always leave
01:30:29
Us okay as leaf because
01:30:34
Of topological order.
01:30:38
So you go in reverse order n minus one and minus two, blah, blah, blah. Up to eat i plus one.
01:30:48
So now you've you've plucked all the nodes up to
01:30:54
i where i is now relief again.
01:30:57
So now, what you get is that the quality of X one up to I
01:31:04
Is just si, si x by I
01:31:10
And then you have product J smaller than I
01:31:14
F G xj exposure.
01:31:25
And now, because I is again a leaf in this reduce graph.
01:31:31
Know,
01:31:34
That there is no x i appearing in this piece right. So for example, I will call this product here. I'll just define this to be a function and this function only depends on x one up to i minus one.
01:31:52
Because there is no x i appearing in any of the parents set
01:32:01
I E. There is no x i by the top political sort property.
user avatar
Unknown Speaker
01:32:12
Right, so
user avatar
Lacoste-Julien Simon
01:32:14
That's again our leaf, kind of like argument.
01:32:23
Okay, so now what you do.
01:32:26
Is you will partition.
01:32:30
The set of nodes one up to i into three pieces there will be I they will be the parent, the parent of i and then there's everything else I'll call it A, so A by definition.
01:32:48
Is just one up to i minus
01:32:53
Sorry, one up to i minus one minus the parents. So I just remove the parents.
01:32:59
Because it's a partnership i minus one minus the parents of
01:33:08
Gay. So then I can write the joint on X one up to I, as the property x i expired. I an ex. So I have three blocks.
user avatar
Unknown Speaker
01:33:23
Okay.
user avatar
Lacoste-Julien Simon
01:33:25
And so now if I want to compute the conditional of x i given x by I
01:33:32
By definition, this is the margin all of exciting expire, which is summation over x A
01:33:39
Of quality x x by x eight
01:33:45
That gives me the marginal an excellent expire I and I need to normalize this by summing over excited. Right. So, this will be summation over x prime
01:33:57
Summation over x A
01:33:59
Be an exciting time.
01:34:02
x by x date.
01:34:10
Okay, so now we wrote the joint, we said, what was the, what was the shape of the joint on X one up to i. Well, we had the factor here and some function, which didn't excite right so let's just rewrite this so the. Oh, did they not use invisible ink again.
01:34:31
Alright, so this is
01:34:34
F of X given x by I
01:34:42
And then I have g of x one up to i minus one.
01:34:52
And somebody is asking how is a define so it's actually
01:34:59
The set
01:35:02
So it's one up to i minus one then they subtract
01:35:09
Pie.
01:35:15
So it's all the elements which are in one up to i without I and without by
01:35:24
Okay, so why did I put a space. Well, the thing is, I can push the some over XE inside because there is no
01:35:33
Because in a there is no by i know i right
user avatar
Unknown Speaker
01:35:38
And so
user avatar
Lacoste-Julien Simon
01:35:41
When I some over XE exciting expire I or not in the summer. So this is just a constant. That's why I can push the some inside
01:35:53
So I have this and then on the denominator I have now. Same thing, summation over x A g of x one up to i minus one.
01:36:07
And then I have my f i x prime given x by I
01:36:14
And then I'm something over x i prime, but because there is no x i.
01:36:20
In the storms. Here again I can factor is it up. So I have your in factories it out.
01:36:30
And so then
01:36:32
Here I just get one.
01:36:35
And here, these things just can't sell that
01:36:39
And so I'm left with just f
01:36:43
X given expire.
01:36:46
Which is what I wanted to
01:36:52
Okay, so. And what I've used it that
01:36:55
There is no
01:36:58
X.
01:37:00
Prime
01:37:02
There.
01:37:10
Okay, so that completes the proof.
01:37:13
Because I was a returnee and so the main property I used was the top logical sort. So that's why I need a DAG.
01:37:19
If it was not a DAG and there was no topological sorting. I could have cycles. Sometimes, and then I will not be able to to marginalize out things and you will not get this this nice property.
01:37:32
And so because we have this property that if I have a member of the family, then the factors which were used for the definition are actually just a conditional from the joint. Then, from now on, we can safely say we can safely right
01:37:54
That the D GM on G is just a set of distribution P such that the joint actually is the product is the product of its conditional
01:38:10
This is not an empty set, and
user avatar
Unknown Speaker
01:38:13
It works.
user avatar
Lacoste-Julien Simon
01:38:17
Okay.
01:38:20
Is there any question.
01:38:26
About this proof.
01:38:40
So let me give you two properties and then
01:38:45
next class I will make things a bit more concrete by looking at the basic three nodes graphs. I'll talk about Markov chain Layton cows and expanding away with, like, more concrete example. Because right now, it's a bit abstract, but let me just mention two properties.
01:39:08
So when you add edges in a graph.
01:39:12
You make the D GM bigger
01:39:16
So adding edges mean you have more distributions in your directive difficult
01:39:23
Because you have bigger factors. And so what I mean by that is, suppose I have a graph, which is Vi n e and then I add edges. So I have g prime which is the same D. But now with the new headset. He prime such that he prime is a superset of he
01:39:46
Then we know that the graphical model on G is a subset of the graphical model on GPU, so they're more distribution. So the more edges you have, the more distributions. Okay.
01:40:06
And so then there's two extremes that will mention, so the smallest graphical model.
01:40:13
Is the one is the empty set of edges like when you add edge you make bigger things right. So if the edge set
01:40:21
Is empty.
01:40:23
Which is basically, in some sense, the trivial graph.
01:40:29
Then you have that the graphical model is actually the smallest and what it contains are fully independent distributions.
01:40:42
Only fully independent
user avatar
Unknown Speaker
01:40:48
Distributions.
user avatar
Lacoste-Julien Simon
01:40:53
Right. HE P of joint is the product over the node of its marginal
01:41:03
And so recall that PM xi could be think thought of x i, given the empty set. Right. So there's no parent
01:41:14
And at the other end of the biggest graphical model is actually containing all distributions. So if you have the complete
01:41:24
Directed graph.
01:41:31
IE for all
01:41:34
I NJ.
01:41:37
Either you have i j, which isn't the edge set or j is or you cannot have both because it has to be a cyclic
01:41:48
But basically you have an edge between every pair of notes.
01:41:52
Okay, so an example on four nodes. Let's say 1234 is I connect one to everything else, then I connect to, to the things I have not connected so far. And then I three there's only one left. Okay, so this is a kind of a complete directed graph.
01:42:15
Then by the chain rule you have that p of x, v is the product.
01:42:25
Of x i given x one up to i minus one.
01:42:31
And so this is like the chain rule.
01:42:37
From the graph I just defined. So one way to have the complete diagram is you connect
01:42:43
Basically one to everything.
01:42:47
up to n to to everything else. It's your dress. So I think this is what you get here.
01:42:53
Yeah, that works.
01:42:56
And so, that implies that all distributions.
01:43:03
Are on XV.
01:43:07
Are in the direction graphical model on the complete graph.
01:43:18
Okay.
01:43:19
So basically you start from the empty graph and you already have all the independent distributions.
01:43:24
Then you add edges, then you get more and more distributions until you have added all the edges possible you get a complete graph, then you actually have all distributions in this in this photograph. Come on. Yeah.
01:43:36
And in particular, the independent distribution is always a subset. So the independent distributions are in all directed graphical model. So there are part of all of them.
01:43:48
So that's important to keep in mind. And so what happens is when you remove edges.
01:43:56
you impose
01:43:58
Basically
01:44:01
More
01:44:03
Factorization constraints. And so you reduce the set of distributions, which which satisfy these constraints.
01:44:21
And we saw by the inefficient of conditional independence that factorization also yield conditional independence assumption and so
01:44:30
We also make more conditional independence assumption, as we remove edges.
01:44:43
And so in the next class will see the basic three nodes structure, which also give interesting condition independence assumptions.
01:44:51
And then we'll talk more about
01:44:54
Their relationship between conditional dependence or stunts assumptions and the graph.
01:44:59
Is there any question remaining question.
01:45:17
Hmm. So Brendan is asking if we can rewrite marginalization using matrix notation, maybe could help to simplify avoid some of these indices
01:45:27
Well, you can certainly rewrite them as matrix product. But the problem is you get very complicated matrices. So you replace the you know Index. Index kind of keeping track of indices with like very complicated matrices. I'm not sure it will simplify that much.
01:45:51
So Jacob is asking
01:45:54
A question, which is, is there a notion of distribution being one which requires all the edges in that graph like ruling out distribution that could be described also by simpler graph, those with fewer edges. So, for example,
01:46:06
The Independent distribution is both in the empty graph there the graphical model and the fully connected graph directed graph model, so it's it's a member of multiple Daejeon
01:46:19
Was there a notion that over, I would like to, to say it's a member of the smallest one.
01:46:24
Yes, and I think I mean, so this is this is something called faithfulness. You will say that the graph is faithful with to the distribution if there is some of kind of these that required since smallest thing.
01:46:39
And when you try to learn a graph from data, you will usually also ask that there's some faithfulness.
01:46:47
assumption about the graph in the sense that, because if there's multiple graph for which distribution could be a doctorate different model.
01:46:55
Then when you see which graph, it is well there's no notion of uniqueness. So by saying it's the faithful graph, then you reduce the set of possible graph. Usually they're actually still multiple graph which could
01:47:07
Be the same size.
01:47:11
But at least it's smaller.
01:47:14
When we talk about model selection for graph, we will see that
01:47:27
So Lauren is asking, oh, what happens if I reverse some edges. So we'll talk about that later, but
01:47:36
The complete diagram is not unique. There's a bunch of different
01:47:41
You know way to make a complete diagram out of end nodes, but they're all all these are equivalent, as the GM, they're all have all distributions in them, so they're all the same set of distributions.
01:47:54
And you have to be careful when you reverse edges because you don't want to create cycle. But if you're just did just use any possible way to connect all the nodes together and it's still a DAG, then it's also a different company graph which is equivalent in terms of set of distributions.
01:48:20
Alright. So last question is there analog to age weights in general graph theory for graphical models.
01:48:34
Right now the age, weight is one in these in these graph properties.
01:48:43
Later, there are some notion, at some point, when you talk about
01:48:48
You can also have weights on on edge.
01:48:52
But they're not directly used for a defining demographic, which is a different. It's a different application area.
01:49:02
Okay. Well, anyway, time is up. So
01:49:08
Let's I'm going to see you on Friday.
01:49:12
Have a nice week